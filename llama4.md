简单的看了一下llama4的blog和其他的一些相关的信息比如hf上的repo和codebase,尽量的大白话描述一下：）
总结如下，发布的llama4包括三个模型,Llama 4 Scout、Llama 4 Maverick 和 Llama 4 Behemoth。
在大模型竞技场（Arena），Llama 4 Maverick 的总排名第二，开源模型排名第一，成为第四个突破 1400 分的大模型。在困难提示词、编程、数学、创意写作等任务中排名均为第一；大幅超越了自家 Llama 3 405B，得分从 1268 提升到了 1417；风格控制排名第五。

llama4 Scout，这次发布的多模态的小模型，可以在单个h100上跑，（可以让每次的回答都一样了），10M上下文窗口，在广泛报道的基准测试中表现优于 Gemma 3、Gemini 2.0 Flash-Lite 和 Mistral 3.1
Llama 4 Maverick Scout的激活参数是一样的但是使用了128个专家，参考专家多点最后的效果好。同类中最好的多模态模型，在广泛报道的基准测试中击败了 GPT-4o 和 Gemini 2.0 Flash，同时在推理和编程方面取得了与新 DeepSeek v3 相当的结果激活参数不到一半。所以我就是有性价比！
上面这俩都是模型蒸馏的，所以效果不错，但是用的是哪个基座模型蒸馏的呢，就是下面这位
Llama 4 Behemoth 是 Meta 目前最强大的模型之一，也是世界上最智能的大型语言模型之一。在多项科学、技术、工程和数学（STEM）基准测试中，Llama 4 Behemoth 的表现优于 GPT-4.5、Claude 3.7 Sonnet 和 Gemini 2.0 Pro。
最后这位大哥现在还正在训练不断进步中，所以还没被派出来。。。

这三位都用了预训练+中期训练+后训练的三段训练式（我给起的名字），其中有几个亮点还是值得学习学习的
MetaP，其能够可靠地设置模型超参数，例如每层的学习率和初始化规模。Meta 发现，选定的超参数在不同批量大小、模型宽度、深度和训练 token 值之间具有良好的迁移性。所以这也就能减少训练的成本

在后训练阶段，Meta 使用 Llama 模型作为评判，移除了超过 50% 的标记为简单（easy）的数据，并在剩余较难的数据集上进行了轻量级监督微调（SFT）。在随后的多模态在线强化学习（RL）阶段，通过精心选择较难的提示，实现了性能的显著提升。

iRoPE：使用无位置嵌入的交错注意力层（interleaved attention layers），并通过推理时的温度缩放来增强长上下文泛化能力。这种架构被称为 iRoPE 架构，其中 i 代表交错（interleaved）注意力层，强调其支持无限上下文长度的长期目标；RoPE 指大多数层中使用的旋转位置嵌入。


原文链接
https://ai.meta.com/blog/llama-4-multimodal-intelligence/
